{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: yellow; font-size: 24px; font-weight: bold;\">\n",
    "    ENSEMBLE LEARNING\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ENSEMBLE + LEARNING :\n",
    "  *  ENSEMBLE means collection of many things ( collection of models/algorithm/combine many models)\n",
    "  *  LEARNING means Machine Learning\n",
    "- Ensemble learning is a machine learning technique that involves combining the predictions of multiple models to create a more robust and accurate prediction that any individual model.\n",
    "- Classification and Regression both task perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogeneous Model(Use Same models): \n",
    "\n",
    "      M1 M2 M3 M4 M5 .............MN  [MODELS] \n",
    "\n",
    "      LR LR LR LR LR .............LR [LOGISTIC REGESSION MODEL USE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterogeneous Model(Use different models): \n",
    "\n",
    "      M1 M2 M3 M4 .............MN  [MODELS] \n",
    "\n",
    "      LR DTC SVC   .............KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CLASSIFICATION - Majority Count (o/p - 0 0 0 0 1 1 0) - final result 0 ( 0's - 5,1's - 2)\n",
    "- REGRESSION -  Average or mean - final result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size: 24px\">ITERATIVE MODEL</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a Machine Learning model uses a group of other models or repeats a process several times then it is called iterative model.\n",
    "- Ex - Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size: 24px\">DIFFERENT TYPES OF ENSEMBLE LEARNING</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Voting\n",
    "2. Bagging - Random Forest\n",
    "3. Boosting - Adaboost,Gradient Boosting(GBM),XGBoost,CataBoost,LightGBM\n",
    "4. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;font-size: 24px\">VOTING</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voting is a fundamental concept in Ensemble Learning where the predictions of multiple models are combined to make a final prediction.\n",
    "- Use for both classification and regression problems.\n",
    "- Two types of Voting :\n",
    "    1. Hard Voting - Voting technique applied (majority count - final result)\n",
    "    2. Soft Voting - Probabillty technique applied - final result average of probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size: 24px\">STACKING</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stacking is also known as Stacked Generalization is an ensemble learning technique that involves combining multiple base models to create a new model,often reffered to as meta model or blender.The key behind stacking is to train several diverse base models and use another model to learn how to best combine or \"Stack\" their prediction.\n",
    "  * Base Models\n",
    "  * Base model prediction\n",
    "  * Meta model(Blender)\n",
    "  * Final prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;font-size: 24px\">BOOSTING</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Boosting is another ensemble learning technique that aims to improve the accuracy of a model by combining the predictions of multiple weak learners.\n",
    "- The key behind idea of Boosting is to correct the errors of the previous models and create a strong ,accurate ensemble .Steps behind:\n",
    "  * Weighted Training\n",
    "  * Instance Weight Adjustment\n",
    "  * Sequential training\n",
    "  * Weighted Voting\n",
    "  * Final Prediction. \n",
    "- Weak Learner - Individual Model\n",
    "- Strong Learner - Combined Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Weak Learner| Strong Learner|\n",
    "| --- | --- | \n",
    "|Perform slightly better than random choice| Performs well,capturing complex relationships|\n",
    "|Simple,low complexity models|Complex,high complexity models|\n",
    "|Less prone to overfitting|May be prone to overfitting if not properly regulrized|\n",
    "|Shallow decision trees,linear models with few features|Deep neural networks,complex decision trees.SVMs with non-linear kernels|\n",
    "|Often used as base models in ensemble methods like bossting or bagging|Typically not used in ensemble learning as they already powerful|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size: 24px\">BOOTSTRAP</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Way of Sampling :\n",
    "  * Row Sampling\n",
    "  * Column Sampling\n",
    "  * Comnine Sampling (Row Sampling + Column Sampling)\n",
    "  * With Replacement (sample-1 [ 1,3],sample-2[ 3,4],sample-3 [ 1,2])\n",
    "  * Without Replacement (sample-1 [ 3,4],sample-2[ 1],sample-3 [ 2,5])\n",
    "- Data is getting repeated called Replcement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row Sampling :\n",
    "   * We are taking a sample from the row but in every sample we are going to take entire column.\n",
    "- Column Sampling:\n",
    "   * All the rows and subset of the column. [Target column must take]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BOOSTRAP : \n",
    "    - ROW SAMPLING + COLUMN SAMPLING  WITH REPLACEMENT OR WITHOUT REPLACEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;font-size: 24px\">BAGGING</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging short for Bootstarp Aggregating is an ensemble learning techinque that invovles traing multiple instances of the same learning algorithm on different subset of the training data.\n",
    "- The primary idea behind bagging is to reduce overfitting and variance,leading to more robust and accurate predictions.\n",
    "- The key steps:\n",
    "  * Boostrap Sampling\n",
    "  * Model Training\n",
    "  * Prediction Aggregation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Bagging| Boosting|Voting|Stacking|\n",
    "| --- | --- | --- | --- |\n",
    "|Homogeneous|Homogeneous|Heterogeneous|Heterogeneous|\n",
    "|Parallel|Sequential|Parallel|-|\n",
    "|Random Forest(Collection of DT)|Adaboost,XGBoost,GB|- | -|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size: 24px\">WHAT IS THE BENEFIT OF ENSEMBLE TECHNIQUE</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Improve Accuracy\n",
    "2. Reduce Overfitting(reduce variance)\n",
    "3. Improve Generalization\n",
    "4. Mitigation of Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple;font-size: 24px\">WHEN TO USE ENSEMBLE TECHNIQUE</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. High variance models\n",
    "2. Highly non-linear relationshhips\n",
    "3. Large and High dimensional Dataset\n",
    "4. Imbalanced Dataset\n",
    "5. Model Combination\n",
    "6. Sequential Learning\n",
    "7. Noisy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generalized Model\n",
    "    * Bias and variance much difference\n",
    "    * Bias and variance almost equal to each other\n",
    "    * low bias and low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Underfitting - Low bias (Train data) and low variance(Test data)\n",
    "- Overfitting - Low bias, high variance and high bias,low variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
