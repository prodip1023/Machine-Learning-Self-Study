{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: yellow; font-size: 24px; font-weight: bold;\">\n",
    "    GRADIENT BOOSTING\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting is a popular machine learning technique used for classification and regression tasks.It is an ensemble learning method that combines the predictions of several weak learners (typically decision trees) to crate a strong predictive model.\n",
    "- The key idea behind gradient boosting is to sequential train new model to correct the errors of the previous ones.\n",
    "- Advanced version of AdaBoosting.\n",
    "- GB = M0 + M1 + M2 + M3 +.........\n",
    "- min_leaf_node = 8\n",
    "- max_leaf_node = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IMAGE](https://media.geeksforgeeks.org/wp-content/uploads/20200721214745/gradientboosting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size: 24px\">STEP WISE GRADIENT BOOSTING INTITUTION</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. Create a base model \n",
    "     - average of the target value (for regression task) [predicted value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute residuals or error\n",
    "   - residual(r) = (actual value - predict value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construct a decision tree consider as inputs(xi) and output as residuals(ri)\n",
    "    - M0 + M1 (base model + 1st Decision Tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Final prediction \n",
    "   - M0 + M1 , M0 + M2 ,....... M0 + MN (This result is overfitted)\n",
    "   - reduce the overfitted to use alpha (alpha is a learning rate)\n",
    "   - M0 + alpha(M1), M0 + alpha(M2),M0 + alpha(M3)......,M0 + alpha(MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction = Base model + alpha(DT1) + alpha(DT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size: 24px\">ADVANTAGES</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. High predictive accuracy\n",
    "2. Handles heterogeneous data(mix datatypes)\n",
    "3. Handles missing values\n",
    "4. Feature importance\n",
    "5. Robust overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-size: 24px\">DISADVANTAGES</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Computational Complexity\n",
    "2. Hyperparameter tuning\n",
    "3. Blackbox model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REF:\n",
    "* https://www.analyticsvidhya.com/blog/2021/09/gradient-boosting-algorithm-a-complete-guide-for-beginners/\n",
    "* https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502\n",
    "* https://www.analytixlabs.co.in/blog/gradient-boosting-algorithm/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
