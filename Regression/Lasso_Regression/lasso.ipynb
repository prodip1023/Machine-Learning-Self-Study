{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue; font-size: 24px; font-weight: bold;\">\n",
    "    LASSO REGRESSION\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LASSO - Stands for LEAST ABSOLUTE SHRINKAGE AND SELECTION OPERATOR\n",
    "- lambda * Modulus of slope\n",
    "- Lasso Regression equation is:\n",
    "\n",
    "        (Equation of line + the sum of squared residuals + lambda * |slope|)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso regression offers some bias but very low variance.\n",
    "- Let us understand that the Ridge regression has L2 penalty term.L2 indicates 'square of slope'.\n",
    "- Lasso regression has L1 penalty term.L1 indicates 'lambda * absolute value of slope'.\n",
    "- The '1' in L1 indicates slope ** 1.\n",
    "- the '1' in the power of the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Lasso Regression is useful to reduce variance.Hence predictions will be more accurate than Ridge Regression.\n",
    "- 2. Ridge Regression considers all the columns in the dataset to predict the final output but Lasso Regression selects only 1 column among all other columns to predict the output.It selects the column that bears maximum influence on the final results.The other columns(or features) are not taken into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;font-size: 24px\">FEATURE SELECTION</span>  ðŸš€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One important use of Lasso Regression is in 'Feature Selection'.\n",
    "- Feature selection means selecting that feature(or column) in the dataset that bears maximum influence on the output.\n",
    "- When there are several columns like x1,x2,x3...Lasso Regression uses the following formula to establish relation between these variables with dependent variable y: \n",
    "    \n",
    "        y = m1x1 + m2x2 + m3x3 +....+ b + sum of squared residuals + lambda * |slope|\n",
    "- m1,m2,m3 are called co-efficients. When a co-efficient has highest value,that will able to affect our output at a highest level.The co-efficient with least value is unimportant since it cannot contribute much for the output.\n",
    "- In feature selection we have to first select the co-efficient with highest value and the corresponding feature(or column) is considered as highly important feature.\n",
    "- If m3 is having highest value,then the column x3 is the feature that is highly important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
