{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue; font-size: 24px; font-weight: bold;\">\n",
    "    RIDGE REGRESSION\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have discussed already three different types of Linear Regression models,namely Simple Linear Regression,Multiple Linear Regression and Polynomial Linear Regression .\n",
    "- Ridge Regression is the another variant of Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most of the times,the data is divided into 2 parts:\n",
    "    1. The data used to train the model\n",
    "    2. The data used to test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are using Simple Linear Regression Model and draw a straight line ,it does not fit the data points in the train data properly.The data points would have lots of deviations from the straight line.This is called \"Bias\".The inability of the model to accurately represent the relationship between the data points is called bias.\n",
    "- If we use another model where insted of a straight line,we can use a wavy line to fit the data points.\n",
    "- In these case,the model(or wavy line) accurately fit the data points without much devaitions.So,in this case,the bias is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let us take Test data now.If we use the same model(wavy line) on the test data,it may not fit the data points accurately.\n",
    "- The difference in fits between datasets is called \"variance\".The wavy line has fit the train data accurately but if could not fit the test data.That means,it fails to predict accurately with future datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: yellow; font-size: 24px; font-weight: bold;\">\n",
    "    BIAS AND VARIANCE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias represents the deviation from the original data and predicted values by the model.\n",
    "- More Bias represents more deviations and hence the model failed to fit the data properly.\n",
    "- Bias is result of inconsistent model being used on the data .To reduce or eliminate bias,we may have to change the model.\n",
    "- We have to use an appropriate model that perfectly fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we used correct model to fits the given data but it fails on the future data,it is known as variance.\n",
    "- The model works well on train data but it fails when used on new data(or test data).When the model works well on train data,it represents low bias.But when failed on new data,it represents high variance.\n",
    "- Hence when bias is low,the varianve will be high and vice-verso.So,bias and variance are inversely proportional to each othe.This is called trade-off between bias and variance.\n",
    "- When bias is high,the variance will be generally low.Similarly,when bias is low,the variance will be high.\n",
    "- What we need is low bias and low variance.That means we want correct model and correct predictions with new data.When we keep bias low,the variance will no be low.\n",
    "- Hence, we need to balance these two to achieve better accurately for the model.\n",
    "- If the model shows high bias and low variance,it is called \"Underfitting\".\n",
    "- If the model shows low bias and high variance,it is called \"Overfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: orange; font-size: 24px; font-weight: bold;\">\n",
    "    REGULARIZATION\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularization is a technique to minimize the variance or overfitting such that it is possible to achieve better accuracy.It minimizes variance without substantial increase in bias.\n",
    "- When regularization is used in Linear Regression Model,we will have the other variations like:\n",
    "    1. Ridge Regression\n",
    "    2. Lasso Regression\n",
    "    3. ElasticNet Regression\n",
    "- These three models are develoed keeping in view of minimize variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue; font-size: 24px; font-weight: bold;\">\n",
    "    RIDGE REGRESSION\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple Linear Regression equation :\n",
    "\n",
    "        ( equation of line  + Sum of squared residuals )\n",
    "- Sum of squared residuals represents the sum of deviations which should be made minimum.Then the model fits the data properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Why we are taking the squares of the devaitions:\n",
    "- When we take deviation alone,the positive and negetive deviations may cancel out.But when we square them,the negative deviations will become positive and add to the overall deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.460000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_squares_deviations = (-1.1)**2+(1.5)**2+(1.2)**2+(-1.6)**2\n",
    "sum_of_squares_deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To control the impact on bias and variance, a regularization parameter by name 'lambda' is used.\n",
    "- When lambda value is increased,it reduces variance.But,if it is increased too much,it will increase bias also.\n",
    "- Hence,tuning the lambda to correct value is impportant to keep both the variance and bias low.\n",
    "- This regularization parameter lambda contributes to another term Ridge Regression.\n",
    "- This term is known as penealty term and is represented as lambda * x square of slope.\n",
    "  \n",
    "  - Simple Linear Regression equation :\n",
    "\n",
    "        ( equation of line  + Sum of squared residuals )\n",
    "\n",
    " -  Ridge Regression equation :\n",
    "\n",
    "        ( equation of line  + Sum of squared residuals + lambda * x square of slope )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here,lambda is called penalty or penalty parameter.Also,the term 'lambda * x square of slope' is called L2 Penalty term.\n",
    "- When lambda = 0,then Ridge Regression will be equal to Simple Linear Regression.\n",
    "- lambda values can be anything from 0 to positive infinity.\n",
    "- Addition of the penalty term is called Regularization which is done in Ridge Regression Model.Let us observe '2' in the name L2 penalty term that indicates '2' in square of slope.i.e. (slope)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since Ridge Regression i san extension to Simple Linear Regression,we can use any of these types on train and test data.\n",
    "- For example,we can use Simple Linear Regression on train data and Ridge Regression on test data while provide predictions.This can be done to fit the train and test data properly and keep the variance and bias low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
